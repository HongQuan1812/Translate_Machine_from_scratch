{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2936819,"sourceType":"datasetVersion","datasetId":1800581}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import PyTorch\nimport torch\nfrom torch import nn\n\n# Import torchvision \nimport torchtext\n\n# Import matplotlib for visualization\nimport matplotlib.pyplot as plt\n\nimport random\n\n# Check versions\n# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchtext version shouldn't be lower than 0.11\nprint(f\"PyTorch version: {torch.__version__}\\ntorchtext version: {torchtext.__version__}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-03T00:33:36.844109Z","iopub.execute_input":"2024-06-03T00:33:36.844461Z","iopub.status.idle":"2024-06-03T00:33:43.008801Z","shell.execute_reply.started":"2024-06-03T00:33:36.844432Z","shell.execute_reply":"2024-06-03T00:33:43.007923Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"PyTorch version: 2.1.2\ntorchtext version: 0.16.2\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"mps\" if torch.backends.mps.is_available() \\\n    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:33:43.010317Z","iopub.execute_input":"2024-06-03T00:33:43.010744Z","iopub.status.idle":"2024-06-03T00:33:43.049301Z","shell.execute_reply.started":"2024-06-03T00:33:43.010710Z","shell.execute_reply":"2024-06-03T00:33:43.048346Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nraw_df = pd.read_csv(\"/kaggle/input/machine-translation-dataset-de-en/translation_train.csv\")\nraw_df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:33:43.051029Z","iopub.execute_input":"2024-06-03T00:33:43.051405Z","iopub.status.idle":"2024-06-03T00:33:43.206794Z","shell.execute_reply.started":"2024-06-03T00:33:43.051339Z","shell.execute_reply":"2024-06-03T00:33:43.205845Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                 english  \\\n2975   A black dog plays with a bit of ice by the fro...   \n13767  A child in a white and green soccer uniform ki...   \n6668   An old man sits on a bench overlooking the water.   \n24171  A group of people are riding down a roller coa...   \n7432   People stand on boat dock waiting for their bo...   \n\n                                                  german  \n2975   Ein schwarzer Hund spielt neben dem gefrorenen...  \n13767  Ein Kind in einer weißen und grünen Fußballuni...  \n6668   Ein alter Mann sitzt auf einer Bank mit Blick ...  \n24171  Eine Gruppe von Menschen fährt eine Achterbahn...  \n7432   Menschen stehen an einer Bootsanlegestelle und...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>german</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2975</th>\n      <td>A black dog plays with a bit of ice by the fro...</td>\n      <td>Ein schwarzer Hund spielt neben dem gefrorenen...</td>\n    </tr>\n    <tr>\n      <th>13767</th>\n      <td>A child in a white and green soccer uniform ki...</td>\n      <td>Ein Kind in einer weißen und grünen Fußballuni...</td>\n    </tr>\n    <tr>\n      <th>6668</th>\n      <td>An old man sits on a bench overlooking the water.</td>\n      <td>Ein alter Mann sitzt auf einer Bank mit Blick ...</td>\n    </tr>\n    <tr>\n      <th>24171</th>\n      <td>A group of people are riding down a roller coa...</td>\n      <td>Eine Gruppe von Menschen fährt eine Achterbahn...</td>\n    </tr>\n    <tr>\n      <th>7432</th>\n      <td>People stand on boat dock waiting for their bo...</td>\n      <td>Menschen stehen an einer Bootsanlegestelle und...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"raw_df['english'][8550], raw_df['german'][8550]","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:33:43.209012Z","iopub.execute_input":"2024-06-03T00:33:43.209322Z","iopub.status.idle":"2024-06-03T00:33:43.216197Z","shell.execute_reply.started":"2024-06-03T00:33:43.209296Z","shell.execute_reply":"2024-06-03T00:33:43.215223Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"('Man with helmet performing a trick while rollerblading.',\n 'Mann mit Helm vollführt ein Kunststück auf Rollerblades.')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"!python -m spacy download de_core_news_sm\n!python -m spacy download en_core_web_sm","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:33:43.217460Z","iopub.execute_input":"2024-06-03T00:33:43.217786Z","iopub.status.idle":"2024-06-03T00:34:20.225055Z","shell.execute_reply.started":"2024-06-03T00:33:43.217760Z","shell.execute_reply":"2024-06-03T00:34:20.223895Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting de-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.3)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.0)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: de-core-news-sm\nSuccessfully installed de-core-news-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.3)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.0)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\n\nen_tokenizer = get_tokenizer(tokenizer = 'spacy', language = \"en_core_web_sm\")\nde_tokenizer = get_tokenizer(tokenizer = 'spacy', language = \"de_core_news_sm\")\n\n# apply tokenizer to our dataset\ntokenized_en_df = raw_df['english'].map(en_tokenizer)\ntokenized_de_df = raw_df['german'].map(de_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:20.226578Z","iopub.execute_input":"2024-06-03T00:34:20.226895Z","iopub.status.idle":"2024-06-03T00:34:29.633909Z","shell.execute_reply.started":"2024-06-03T00:34:20.226858Z","shell.execute_reply":"2024-06-03T00:34:29.633140Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Create vocab","metadata":{}},{"cell_type":"code","source":"from torchtext.vocab import build_vocab_from_iterator\n\nen_vocab = build_vocab_from_iterator(\n    tokenized_en_df,\n    min_freq=2,\n    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n    special_first=True,\n)\nen_vocab.set_default_index(en_vocab['<unk>'])\n\nde_vocab = build_vocab_from_iterator(\n    tokenized_de_df,\n    min_freq=2,\n    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n    special_first=True,\n)\nde_vocab.set_default_index(de_vocab['<unk>'])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:29.634997Z","iopub.execute_input":"2024-06-03T00:34:29.635492Z","iopub.status.idle":"2024-06-03T00:34:30.014466Z","shell.execute_reply.started":"2024-06-03T00:34:29.635466Z","shell.execute_reply":"2024-06-03T00:34:30.013456Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(f\"length of english vocabulary: {len(en_vocab)}\")\nprint(f\"length of german vocabulary: {len(de_vocab)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.015682Z","iopub.execute_input":"2024-06-03T00:34:30.015980Z","iopub.status.idle":"2024-06-03T00:34:30.021114Z","shell.execute_reply.started":"2024-06-03T00:34:30.015955Z","shell.execute_reply":"2024-06-03T00:34:30.020003Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"length of english vocabulary: 6191\nlength of german vocabulary: 8014\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchtext import transforms\n\nen_transform = transforms.Sequential(\n    ## converts the sentences to indices based on given vocabulary\n    transforms.VocabTransform(vocab=en_vocab),\n\n    ## Add <sos> at beginning of each sentence. 1 because the index for <sos> in vocabulary is 1 as seen in previous section\n    transforms.AddToken(en_vocab['<sos>'], begin=True),\n\n    ## Add <eos> at end of each sentence. 2 because the index for <eos> in vocabulary is 2 as seen in previous section\n    transforms.AddToken(en_vocab['<eos>'], begin=False),\n    \n    ## converts data into tensor\n    transforms.ToTensor(),\n    \n#     ## padding\n#     transforms.PadTransform(\n#         max_length = tokenized_en_df.map(len).max() + 2, #2 for <sos> and <eos>\n#         pad_value = 0)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.022535Z","iopub.execute_input":"2024-06-03T00:34:30.022870Z","iopub.status.idle":"2024-06-03T00:34:30.033303Z","shell.execute_reply.started":"2024-06-03T00:34:30.022841Z","shell.execute_reply":"2024-06-03T00:34:30.032442Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torchtext import transforms\n\nde_transform = transforms.Sequential(\n    ## converts the sentences to indices based on given vocabulary\n    transforms.VocabTransform(vocab=de_vocab),\n\n    ## Add <sos> at beginning of each sentence. 1 because the index for <sos> in vocabulary is 1 as seen in previous section\n    transforms.AddToken(de_vocab['<sos>'], begin=True),\n    \n    ## converts data into tensor\n    transforms.ToTensor(),\n    \n#     ## padding\n#     transforms.PadTransform(\n#         max_length = tokenized_de_df.map(len).max() + 1, #1 for <sos> \n#         pad_value = 0)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.037178Z","iopub.execute_input":"2024-06-03T00:34:30.037447Z","iopub.status.idle":"2024-06-03T00:34:30.047604Z","shell.execute_reply.started":"2024-06-03T00:34:30.037424Z","shell.execute_reply":"2024-06-03T00:34:30.046887Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from torchtext import transforms\n\nlabel_transform = transforms.Sequential(\n    ## converts the sentences to indices based on given vocabulary\n    transforms.VocabTransform(vocab=de_vocab),\n\n    ## Add <eos> at end of each sentence. 2 because the index for <eos> in vocabulary is 2 as seen in previous section\n    transforms.AddToken(de_vocab['<eos>'], begin=False),\n    \n    ## converts data into tensor\n    transforms.ToTensor(),\n    \n#     ## padding\n#     transforms.PadTransform(\n#         max_length = tokenized_de_df.map(len).max() + 1, #1 for <sos> \n#         pad_value = 0)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.048551Z","iopub.execute_input":"2024-06-03T00:34:30.048785Z","iopub.status.idle":"2024-06-03T00:34:30.058805Z","shell.execute_reply.started":"2024-06-03T00:34:30.048765Z","shell.execute_reply":"2024-06-03T00:34:30.057936Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Make a dataset","metadata":{}},{"cell_type":"code","source":"# Write a custom dataset class (inherits from torch.utils.data.Dataset)\nfrom torch.utils.data import Dataset\n\n\n# 1. Subclass torch.utils.data.Dataset\nclass En_De_DatasetCustom(Dataset):\n    \n    # 2. Initialize with a target_dir and transform (optional) parameter\n    def __init__(self, df, transform, is_test = False):\n        \n    # 3. Create class attributes\n        # Get all image paths\n        self.df = df\n        # Setup transforms\n        self.transform = transform\n        # Check if df is used for test\n        self.is_test = is_test\n    \n    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n    def __len__(self) -> int:\n        \"Returns the total number of samples.\"\n        return len(self.df)\n    \n    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n    def __getitem__(self, index: int):\n        \"Returns one sample of data, data and label (X, y).\"\n        if self.is_test == False:\n            tokenized_en_text = en_tokenizer(self.df['english'].values[index])\n            tokenized_de_text = de_tokenizer(self.df['german'].values[index])\n            transformed_en_text = self.transform['en'](tokenized_en_text)\n            transformed_de_text = self.transform['de'](tokenized_de_text)\n            transformed_label = self.transform['label'](tokenized_de_text)\n            return transformed_en_text, transformed_de_text, transformed_label # return data, label (X, y)\n        else:\n            tokenized_en_text = en_tokenizer(self.df['english'].values[index])\n            transformed_en_text = self.transform['en'](tokenized_en_text)\n            return transformed_en_text","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.059845Z","iopub.execute_input":"2024-06-03T00:34:30.060136Z","iopub.status.idle":"2024-06-03T00:34:30.071187Z","shell.execute_reply.started":"2024-06-03T00:34:30.060113Z","shell.execute_reply":"2024-06-03T00:34:30.070314Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"En_De_Dataset = En_De_DatasetCustom(\n    df = raw_df,\n    transform = {'en': en_transform, \n                 'de': de_transform,\n                 'label': label_transform}\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.072143Z","iopub.execute_input":"2024-06-03T00:34:30.072402Z","iopub.status.idle":"2024-06-03T00:34:30.085059Z","shell.execute_reply.started":"2024-06-03T00:34:30.072380Z","shell.execute_reply":"2024-06-03T00:34:30.084199Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"En_De_Dataset[1]","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.086161Z","iopub.execute_input":"2024-06-03T00:34:30.086475Z","iopub.status.idle":"2024-06-03T00:34:30.125594Z","shell.execute_reply.started":"2024-06-03T00:34:30.086446Z","shell.execute_reply":"2024-06-03T00:34:30.124750Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(tensor([   1,  165,   36,    7,  335,  287,   17, 1224,    4,  758, 4496, 2957,\n            5,    2]),\n tensor([   1,   84,   31,   10,  847, 2208,   15,    3,    4]),\n tensor([  84,   31,   10,  847, 2208,   15,    3,    4,    2]))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Split dataset into train and validate","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader, random_split\n\n# Define the sizes of the splits\ntrain_size = int(0.8 * len(En_De_Dataset))\nval_size = len(En_De_Dataset) - train_size\n\n# Use random_split to split the dataset\ntrain_dataset, val_dataset = random_split(En_De_Dataset, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.126670Z","iopub.execute_input":"2024-06-03T00:34:30.127009Z","iopub.status.idle":"2024-06-03T00:34:30.139474Z","shell.execute_reply.started":"2024-06-03T00:34:30.126979Z","shell.execute_reply":"2024-06-03T00:34:30.138745Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Prepare dataloader","metadata":{}},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\n\ndef collate_fn(batch):\n    # Separate data and labels\n    en_sequences, de_sequences, labels = zip(*batch)\n    # Pad the sequences\n    padded_en_sequences = pad_sequence(en_sequences, batch_first=True, padding_value=0)\n    padded_de_sequences = pad_sequence(de_sequences, batch_first=True, padding_value=0)\n    padded_labels = pad_sequence(labels, batch_first=True, padding_value=0)\n\n    \n    return padded_en_sequences, padded_de_sequences, padded_labels","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.140666Z","iopub.execute_input":"2024-06-03T00:34:30.141012Z","iopub.status.idle":"2024-06-03T00:34:30.147415Z","shell.execute_reply.started":"2024-06-03T00:34:30.140983Z","shell.execute_reply":"2024-06-03T00:34:30.146591Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport os\n\n# Setup the batch size hyperparameter\nBATCH_SIZE = 512\nNUM_CORES = os.cpu_count()\n\n# Turn datasets into iterables (batches)\ntrain_dataloader = DataLoader(\n    train_dataset, # dataset to turn into iterable\n    batch_size=BATCH_SIZE, # how many samples per batch? \n    shuffle=True, # shuffle data every epoch?\n    num_workers = NUM_CORES,\n    pin_memory =True,\n    collate_fn=collate_fn\n    \n)\n\nval_dataloader = DataLoader(\n    val_dataset,\n    batch_size=1,\n    shuffle=False, # don't necessarily have to shuffle the testing data\n    num_workers = NUM_CORES,\n    pin_memory =True,\n    collate_fn=collate_fn\n                            \n)\n\n# Let's check out what we've created\nprint(f\"Dataloaders: {train_dataloader, val_dataloader}\") \nprint(f\"Length of training dataset: {len(train_dataloader.dataset)}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataset: {len(val_dataloader.dataset)}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {1}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.148525Z","iopub.execute_input":"2024-06-03T00:34:30.148847Z","iopub.status.idle":"2024-06-03T00:34:30.159581Z","shell.execute_reply.started":"2024-06-03T00:34:30.148814Z","shell.execute_reply":"2024-06-03T00:34:30.158759Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7fcd7670cdf0>, <torch.utils.data.dataloader.DataLoader object at 0x7fcd7670dfc0>)\nLength of training dataset: 23200\nLength of train dataloader: 46 batches of 512\nLength of val dataset: 5800\nLength of val dataloader: 5800 batches of 1\n","output_type":"stream"}]},{"cell_type":"code","source":"input_sequences_batch, output_sequences_batch, labels_batch = next(iter(train_dataloader))\ninput_sequences_batch.shape, output_sequences_batch.shape, labels_batch.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.160696Z","iopub.execute_input":"2024-06-03T00:34:30.161109Z","iopub.status.idle":"2024-06-03T00:34:30.970741Z","shell.execute_reply.started":"2024-06-03T00:34:30.161070Z","shell.execute_reply":"2024-06-03T00:34:30.969712Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(torch.Size([512, 30]), torch.Size([512, 32]), torch.Size([512, 32]))"},"metadata":{}}]},{"cell_type":"code","source":"input_sequences_batch, output_sequences_batch, labels_batch = next(iter(val_dataloader))\ninput_sequences_batch.shape, output_sequences_batch.shape, labels_batch.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:30.972186Z","iopub.execute_input":"2024-06-03T00:34:30.972483Z","iopub.status.idle":"2024-06-03T00:34:31.086062Z","shell.execute_reply.started":"2024-06-03T00:34:30.972455Z","shell.execute_reply":"2024-06-03T00:34:31.084914Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(torch.Size([1, 13]), torch.Size([1, 11]), torch.Size([1, 11]))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import math\nclass PositionalEncoding(torch.nn.Module):\n    def __init__(self, \n                 d_model = 512,\n                 max_length = 5000):\n        \n        super().__init__()\n        \n        # Initialize Positional Encoding with zeros\n        pe = torch.zeros(max_length, d_model)\n        ### pe_shape = [max_length,d_model]\n        \n        # Get the position of tokens in a sequence\n        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(dim = 1)\n        ### position_shape = [max_length,1]\n        \n        # Compute positional embedding\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(dim = 0)\n        ### pe_shape = [1,max_length,d_model]\n        \n        self.register_buffer('pe', pe) # we don't train the pe\n        \n    def forward(self,x):\n        ### x_shape = [N,seq,d_model]\n        \n        out = x + self.pe[:,:x.shape[1]]\n        ### output_shape = [N,seq,d_model]\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.087507Z","iopub.execute_input":"2024-06-03T00:34:31.087819Z","iopub.status.idle":"2024-06-03T00:34:31.096908Z","shell.execute_reply.started":"2024-06-03T00:34:31.087791Z","shell.execute_reply":"2024-06-03T00:34:31.096029Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class InputEmbedding(torch.nn.Module):\n    def __init__(self, vocab, d_model = 512, max_length = 5000):\n        super().__init__()\n        \n        self.embedding = torch.nn.Embedding(\n            num_embeddings = len(vocab), \n            embedding_dim = d_model, \n            padding_idx = vocab['<pad>']\n        )\n        self.pe = PositionalEncoding(\n            d_model = d_model,\n            max_length = max_length\n        )\n        \n    def forward(self,x):\n        ### x_shape = [N,seq]\n        \n        out = self.embedding(x)\n        ### output_embedding_shape = [N,seq,d_model]\n        \n        out = self.pe(out)\n        ### output_pe_shape = [N,seq,d_model]\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.098196Z","iopub.execute_input":"2024-06-03T00:34:31.098500Z","iopub.status.idle":"2024-06-03T00:34:31.108143Z","shell.execute_reply.started":"2024-06-03T00:34:31.098476Z","shell.execute_reply":"2024-06-03T00:34:31.107259Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class Transformer_model(torch.nn.Module):\n    def __init__(self, \n                 d_model,\n                 nhead,\n                 dim_feedforward,\n                 output_size,\n                 src_vocab, tgt_vocab,\n                 max_length = 5000):\n        \n        super().__init__()\n        \n        self.max_length = max_length\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n        \n        # The input Embedding\n        self.src_embedding = InputEmbedding(\n            vocab = src_vocab,\n            d_model = d_model,\n            max_length = max_length\n        )\n        \n        self.tgt_embedding = InputEmbedding(\n            vocab = tgt_vocab,\n            d_model = d_model,\n            max_length = max_length\n        )\n        \n        # The core encoder-decoder transformer\n        self.encoder_layer = torch.nn.TransformerEncoderLayer(\n            d_model = d_model,\n            nhead = nhead,\n            dim_feedforward = dim_feedforward,\n            batch_first = True,\n            bias = True\n        )\n\n        self.decoder_layer = torch.nn.TransformerDecoderLayer(\n            d_model = d_model,\n            nhead = nhead,\n            dim_feedforward = dim_feedforward,\n            batch_first = True,\n            bias = True\n        )\n\n        self.encoder_transformer = torch.nn.TransformerEncoder(\n            encoder_layer = self.encoder_layer,\n            num_layers = 1\n        )\n\n        self.decoder_transformer = torch.nn.TransformerDecoder(\n            decoder_layer = self.decoder_layer,\n            num_layers = 1\n        )\n\n        # The classifier\n        self.classifier = torch.nn.Sequential(\n            torch.nn.LayerNorm(d_model),\n            torch.nn.Linear(d_model, d_model),\n            torch.nn.ReLU(),\n            torch.nn.LayerNorm(d_model),\n            torch.nn.Linear(d_model, output_size),\n            torch.nn.LayerNorm(output_size)\n        )\n        \n        \n    def do_training(self, encoder_input, decoder_input, epoch):\n        # encoder_input_shape = [N,seq_en], decoder_input_shape = [N,seq_de]\n\n        encoder_padding_mask = generate_key_padding_mask(encoder_input)\n        # encoder_padding_mask_shape = [N,seq_en]\n        \n        encoder_embedding = self.src_embedding(encoder_input)\n        # encoder_embedding_shape = [N,seq_en,d_model]\n        \n        encoder_output = self.encoder_transformer(\n            src = encoder_embedding,\n            src_key_padding_mask = encoder_padding_mask\n        )\n        # encoder_output_shape = [N,seq_en,d_model]\n        \n        decoder_mask = generate_square_mask(decoder_input.shape[1])\n        # decoder_mask_shape = [seq_de,seq_de]\n\n        decoder_padding_mask = generate_key_padding_mask(decoder_input)\n        # decoder_padding_mask_shape = [N,seq_de]\n\n        decoder_embedding = self.tgt_embedding(decoder_input)\n        # encoder_embedding_shape = [N,seq_de,d_model]\n\n        decoder_output = self.decoder_transformer(\n            tgt = decoder_embedding,\n            tgt_mask = decoder_mask,\n            tgt_key_padding_mask = decoder_padding_mask,\n            memory = encoder_output,\n            memory_key_padding_mask = encoder_padding_mask\n        )\n        # decoder_output_shape = [N,seq_de,d_model]\n\n        decoder_output = self.classifier(decoder_output)\n        # decoder_output_shape = [N,seq_de,tgt_vocab_size]\n        \n        return decoder_output\n    \n    def make_generation(self, encoder_input, search_strategy = 'beam_search', beam_size = 7):\n        \"\"\"\n            Batch_size must be one \n        \"\"\"\n        assert encoder_input.shape[0] == 1, \"batch_size != 1\"\n        \n        if search_strategy == 'beam_search':\n            generated_sequence = self.Beam_Search(beam_size, encoder_input)\n        else:\n            generated_sequence = self.Greedy_Search(encoder_input)\n        \n        return generated_sequence","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.109423Z","iopub.execute_input":"2024-06-03T00:34:31.109695Z","iopub.status.idle":"2024-06-03T00:34:31.125362Z","shell.execute_reply.started":"2024-06-03T00:34:31.109673Z","shell.execute_reply":"2024-06-03T00:34:31.124476Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def generate_square_mask(seq):\n    mask = torch.ones(size = (seq, seq), \n                      device=device if device == 'cuda' else 'cpu')\n    mask = (torch.triu(mask)).transpose(0, 1)\n    mask = mask.type(torch.float32).masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.126509Z","iopub.execute_input":"2024-06-03T00:34:31.126818Z","iopub.status.idle":"2024-06-03T00:34:31.137775Z","shell.execute_reply.started":"2024-06-03T00:34:31.126787Z","shell.execute_reply":"2024-06-03T00:34:31.137051Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def generate_key_padding_mask(X):\n    # X_shape = [N,seq]\n    padding_mask = (X == 0)\n    return padding_mask.type(torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.138720Z","iopub.execute_input":"2024-06-03T00:34:31.138989Z","iopub.status.idle":"2024-06-03T00:34:31.150352Z","shell.execute_reply.started":"2024-06-03T00:34:31.138968Z","shell.execute_reply":"2024-06-03T00:34:31.149575Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def Greedy_step(self, output_at_t):\n    # output_at_t = [N,1,vocab_size]\n    \n    top_prob, top_idx = output_at_t.topk(1, dim = 2) \n    # top_idx_shape = [N,1,1]\n\n    top_idx = top_idx.squeeze(1).detach()\n    # top_idx_shape = [N,1]\n\n    return top_idx\n\ndef Greedy_Search(self, encoder_input):\n    # encoder_input_shape = [N,seq_en]\n\n    encoder_padding_mask = generate_key_padding_mask( encoder_input)\n    # encoder_padding_mask_shape = [N,seq_en]\n\n    encoder_embedding = self.src_embedding(encoder_input)\n    # encoder_embedding_shape = [N,seq_en,d_model]\n\n    encoder_output = self.encoder_transformer(\n        src = encoder_embedding,\n        src_key_padding_mask = encoder_padding_mask\n    )\n    # encoder_output_shape = [N,seq_en,d_model]\n            \n    \n    batch_size = encoder_input.shape[0]\n    inputs = torch.ones(\n        size = (batch_size, 1),\n        dtype = torch.long,\n        device = device if device == 'cuda' else 'cpu'\n    ) * self.tgt_vocab['<sos>']\n    # input_shape = [N,1]\n\n    for i in range(self.max_length):\n        inputs_mask = generate_square_mask(inputs.shape[1])\n        # decoder_mask_shape = [seq_intput,seq_input]\n\n        inputs_padding_mask = generate_key_padding_mask(inputs)\n        # decoder_padding_mask_shape = [N,seq_input]\n\n        inputs_embedding = self.tgt_embedding(inputs)\n        # inputs_embedding_shape = [N,seq_input,d_model]\n\n        outputs = self.decoder_transformer(\n            tgt = inputs_embedding,\n            memory = encoder_output,\n            tgt_mask = inputs_mask,\n            tgt_key_padding_mask = inputs_padding_mask,\n            memory_key_padding_mask = encoder_padding_mask\n        )\n        # output_shape = [N,seq_input,d_model]\n        \n        outputs = outputs[:,-1].unsqueeze(dim=1)\n        # output[:,-1]_shape = [N,d_model], output_shape = [N,1,d_model]\n\n        outputs = self.classifier(outputs)\n        # output_shape = [N,1,tgt_vocab_size]\n\n        next_words = self.Greedy_step(torch.softmax(outputs,dim=2))\n        # inputs_shape = [N,1]\n        \n        inputs = torch.cat([inputs, next_words], dim = 1)\n        # inputs_shape = [N,seq_input]\n        \n        if next_words.item() == self.tgt_vocab['<eos>']:\n            break\n        \n    generated_sequence = inputs\n    # generated_sequence_shape = [N,seq_input]\n        \n    return generated_sequence.squeeze(0)\n\nTransformer_model.Greedy_step = Greedy_step\nTransformer_model.Greedy_Search = Greedy_Search","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.151442Z","iopub.execute_input":"2024-06-03T00:34:31.151696Z","iopub.status.idle":"2024-06-03T00:34:31.163690Z","shell.execute_reply.started":"2024-06-03T00:34:31.151676Z","shell.execute_reply":"2024-06-03T00:34:31.162761Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def Beam_step(self, beam_size, output_at_t):\n    # output_at_t = [N,1,vocab_size]\n    \n    top_prob, top_idx = output_at_t.topk(beam_size, dim = 2) \n    # top_idx_shape = [N,1,beam_size]\n    # top_prob_shape = [N,1,beam_size]\n\n    top_idx = top_idx.squeeze(1).detach()\n    # top_idx_shape = [N,beam_size]\n\n    top_prob = top_prob.squeeze(1).detach()\n    # top_prob_shape = [N,beam_size]\n    \n    return top_idx, top_prob\n\ndef Beam_Search(self, beam_size, encoder_input):\n    # encoder_input_shape = [N,seq_en]\n\n    encoder_padding_mask = generate_key_padding_mask(encoder_input)\n    # encoder_padding_mask_shape = [N,seq_en]\n\n    encoder_embedding = self.src_embedding(encoder_input)\n    # encoder_embedding_shape = [N,seq_en,d_model]\n\n    encoder_output = self.encoder_transformer(\n        src = encoder_embedding,\n        src_key_padding_mask = encoder_padding_mask\n    )\n    # encoder_output_shape = [N,seq_en,d_model]\n            \n    \n    batch_size = encoder_input.shape[0]\n    inputs = torch.ones(\n        size = (batch_size, 1),\n        dtype = torch.long,\n        device = device if device == 'cuda' else 'cpu'\n    ) * self.tgt_vocab['<sos>']\n    # input_shape = [N,1]\n    \n    candidate_sequence = inputs\n    # candidate_sequence_shape = [N,1]\n    \n    score = torch.log(torch.ones(size = [batch_size, 1], \n                                device = device if device == 'cuda' else 'cpu'))\n    # score_shape = [N,1]\n    \n    candidates = [(candidate_sequence, score)]\n    \n    finished_candidates = []\n    for i in range(self.max_length):\n        \n        new_candidates = []\n        for candidate_sequence, score in candidates:\n            # candidates_shape = beam_size * ()\n            # candidate_sequence_shape = [N,seq]\n            # score_shape = [N,1]\n\n            last_token = candidate_sequence[:,-1].unsqueeze(-1)\n            # last_token_shape = [N,1]\n            \n            if last_token.item() == self.tgt_vocab['<eos>']:\n                finished_candidates.append((candidate_sequence, score))\n                continue\n            \n            inputs_mask = generate_square_mask(candidate_sequence.shape[1])\n            # decoder_mask_shape = [seq_intput,seq_input]\n\n            inputs_padding_mask = generate_key_padding_mask(candidate_sequence)\n            # decoder_padding_mask_shape = [N,seq_input]\n\n            inputs_embedding = self.tgt_embedding(candidate_sequence)\n            # inputs_embedding_shape = [N,seq_input,d_model]\n\n            outputs = self.decoder_transformer(\n                tgt = inputs_embedding,\n                memory = encoder_output,\n                tgt_mask = inputs_mask,\n                tgt_key_padding_mask = inputs_padding_mask,\n                memory_key_padding_mask = encoder_padding_mask\n            )\n            # output_shape = [N,seq_input,d_model]\n            \n            outputs = outputs[:,-1].unsqueeze(dim=1)\n            # output[:,-1]_shape = [N,d_model], output_shape = [N,1,d_model]\n\n            outputs = self.classifier(outputs)\n            # output_shape = [N,1,tgt_vocab_size]\n            \n            top_tokens, top_probs = self.Beam_step(beam_size = beam_size, \n                                                   output_at_t = torch.softmax(outputs,dim=2))\n            # top_tokens = [N,beam_size]\n            # top_probs = [N,beam_size]\n            \n            for j in range(beam_size):\n                new_candidate_sequence = torch.cat([candidate_sequence, top_tokens[:,j].unsqueeze(-1)], dim = 1) # top_tokens[:,j].unsqueeze(-1) -> shape: [N,1]\n                # new_candidate_sequence_shape = [N,seq+1]\n                new_score = score + torch.log(top_probs[:,j].unsqueeze(-1)) # top_probs[:,j].unsqueeze(-1) -> shape: [N,1]\n                # new_score_shape = [N,1]\n                new_candidates.append((new_candidate_sequence, new_score))\n            \n        \n            new_candiadates = sorted(new_candidates, key=lambda x: x[1]/len(x[0]), reverse=True)\n            candidates = new_candidates[:beam_size]\n        \n        \n        if all([candidate_sequence[:,-1].unsqueeze(-1) == self.tgt_vocab['<eos>'] \\\n                for candidate_sequence, _, in candidates]):\n            break\n        \n        if len(finished_candidates) == beam_size/2:\n            break\n            \n    candidates.extend(finished_candidates)\n    candidates = sorted(candidates, key=lambda x: x[1]/len(x[0]), reverse=True)\n        \n    return candidates[0][0].squeeze(0)\n\nTransformer_model.Beam_step = Beam_step\nTransformer_model.Beam_Search = Beam_Search","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.164810Z","iopub.execute_input":"2024-06-03T00:34:31.165078Z","iopub.status.idle":"2024-06-03T00:34:31.183644Z","shell.execute_reply.started":"2024-06-03T00:34:31.165058Z","shell.execute_reply":"2024-06-03T00:34:31.182650Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def convert_to_sentence(sequence, vocab):\n\n    try:\n        sos_idx = list(sequence).index(vocab['<sos>'])\n    except ValueError as Error:\n        sos_idx = -1\n    \n    try:\n        eos_idx = list(sequence).index(vocab['<eos>'])\n    except ValueError as Error:\n        eos_idx = -1\n        \n    if eos_idx != -1:\n        sequence = vocab.lookup_tokens(list(sequence)[sos_idx+1: eos_idx])\n    else:\n        sequence = vocab.lookup_tokens(list(sequence)[sos_idx+1:])\n        \n    sentences = ' '.join(sequence)\n    \n    return sentences","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.184870Z","iopub.execute_input":"2024-06-03T00:34:31.185200Z","iopub.status.idle":"2024-06-03T00:34:31.197508Z","shell.execute_reply.started":"2024-06-03T00:34:31.185169Z","shell.execute_reply":"2024-06-03T00:34:31.196809Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model_2 = Transformer_model(\n    d_model = 512,          \n    nhead = 8,\n    dim_feedforward = 2048,\n    output_size = len(de_vocab),\n    src_vocab = en_vocab, \n    tgt_vocab = de_vocab,\n    max_length = 50\n)\nmodel_2.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.204134Z","iopub.execute_input":"2024-06-03T00:34:31.204375Z","iopub.status.idle":"2024-06-03T00:34:31.507959Z","shell.execute_reply.started":"2024-06-03T00:34:31.204355Z","shell.execute_reply":"2024-06-03T00:34:31.506834Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Transformer_model(\n  (src_vocab): Vocab()\n  (tgt_vocab): Vocab()\n  (src_embedding): InputEmbedding(\n    (embedding): Embedding(6191, 512, padding_idx=0)\n    (pe): PositionalEncoding()\n  )\n  (tgt_embedding): InputEmbedding(\n    (embedding): Embedding(8014, 512, padding_idx=0)\n    (pe): PositionalEncoding()\n  )\n  (encoder_layer): TransformerEncoderLayer(\n    (self_attn): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n    )\n    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (dropout1): Dropout(p=0.1, inplace=False)\n    (dropout2): Dropout(p=0.1, inplace=False)\n  )\n  (decoder_layer): TransformerDecoderLayer(\n    (self_attn): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n    )\n    (multihead_attn): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n    )\n    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (dropout1): Dropout(p=0.1, inplace=False)\n    (dropout2): Dropout(p=0.1, inplace=False)\n    (dropout3): Dropout(p=0.1, inplace=False)\n  )\n  (encoder_transformer): TransformerEncoder(\n    (layers): ModuleList(\n      (0): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (decoder_transformer): TransformerDecoder(\n    (layers): ModuleList(\n      (0): TransformerDecoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (multihead_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (classifier): Sequential(\n    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (1): Linear(in_features=512, out_features=512, bias=True)\n    (2): ReLU()\n    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (4): Linear(in_features=512, out_features=8014, bias=True)\n    (5): LayerNorm((8014,), eps=1e-05, elementwise_affine=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"sample = input_sequences_batch[0].unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.509197Z","iopub.execute_input":"2024-06-03T00:34:31.509502Z","iopub.status.idle":"2024-06-03T00:34:31.514034Z","shell.execute_reply.started":"2024-06-03T00:34:31.509477Z","shell.execute_reply":"2024-06-03T00:34:31.513143Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"sequence = model_2.make_generation(sample.to(device))\nsequence","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:31.515108Z","iopub.execute_input":"2024-06-03T00:34:31.515443Z","iopub.status.idle":"2024-06-03T00:34:34.049848Z","shell.execute_reply.started":"2024-06-03T00:34:31.515409Z","shell.execute_reply":"2024-06-03T00:34:34.048957Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"tensor([   1,  120,  593, 3554, 4250, 2968, 3206, 7643, 6060, 4378, 3853, 6198,\n        4892, 5744, 7689, 1334, 3724, 4425,   49, 7238, 5649, 5663, 1085, 3488,\n        3702, 4599, 5740, 3991, 3553,  768, 4533, 2678, 7825, 2826, 6112, 7360,\n        4212, 6746, 6725, 3272,  264, 7504, 6273, 5568, 3268, 1159, 1508, 3822,\n        4385, 7351, 3337], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"sentence = convert_to_sentence(sequence, de_vocab)\nsentence","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:34.051727Z","iopub.execute_input":"2024-06-03T00:34:34.052276Z","iopub.status.idle":"2024-06-03T00:34:34.061523Z","shell.execute_reply.started":"2024-06-03T00:34:34.052240Z","shell.execute_reply":"2024-06-03T00:34:34.060587Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'Gras leeren poliert riesiger Struktur Bulldozer mexikanische Hebebühne Baseballplatz Meeresufer Kiosk Steaks Campingstühlen pastellfarbenen steinigen Fallschirmspringen Bürgersteigs neben bewegungslos Betonblock Birthday Mänteln fertigen Dirtbike Interessantes Campen Steinwand plantscht davor Geschirrspüler Ziege streitet Eiswagen Holztreppe ethnischer letzte Sommerkleider Sitzender Kamin Trikot hellrotes Latzhosen Augen-Makeup Inneren Schäferhund Waldweg Kälte Basketbälle erobern Radio'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Set seeds\ndef set_seeds(seed: int=42):\n    \"\"\"Sets random sets for torch operations.\n\n    Args:\n        seed (int, optional): Random seed to set. Defaults to 42.\n    \"\"\"\n    # Set the seed for general torch operations\n    torch.manual_seed(seed)\n    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n    torch.cuda.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:34.062720Z","iopub.execute_input":"2024-06-03T00:34:34.063164Z","iopub.status.idle":"2024-06-03T00:34:34.105267Z","shell.execute_reply.started":"2024-06-03T00:34:34.063132Z","shell.execute_reply":"2024-06-03T00:34:34.104300Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from timeit import default_timer as timer \n\ndef print_train_time(start: float, end: float, device: torch.device = None):\n    total_time = end - start\n    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n    return total_time","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:34.106454Z","iopub.execute_input":"2024-06-03T00:34:34.106795Z","iopub.status.idle":"2024-06-03T00:34:34.115539Z","shell.execute_reply.started":"2024-06-03T00:34:34.106763Z","shell.execute_reply":"2024-06-03T00:34:34.114648Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n               data_loader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               epoch,\n               device: torch.device = 'cpu'):\n    \n    if device != 'cpu':\n        model.to(device)\n    \n    train_loss = 0\n    model.train()\n    for batch, (X_encoder,X_decoder, y) in enumerate(data_loader):\n        # Send data to GPU\n        if device != 'cpu':\n            X_encoder, X_decoder, y = X_encoder.to(device), X_decoder.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model.do_training(X_encoder, X_decoder, epoch)\n            # y_pred_shape = [N,seq_de,vocab_size]\n        \n        # 2. Calculate loss\n        loss = loss_fn(y_pred.view(-1,y_pred.shape[2]), y.view(-1))\n        train_loss += loss\n\t\t\t\t\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n    # Calculate loss and accuracy per epoch and print out what's happening\n    train_loss /= len(data_loader)\n\n    return train_loss\n\ndef test_step(model: torch.nn.Module,\n              data_loader: torch.utils.data.DataLoader,\n              device: torch.device = 'cpu'):\n    \n    if device != 'cpu':\n        model.to(device)\n\n    model.eval() \n    with torch.inference_mode(): \n        \n        X_encoder,X_decoder, y = list(data_loader)[7]\n        \n        # Send data to GPU\n        if device != 'cpu':\n            X_encoder, X_decoder, y = X_encoder.to(device), X_decoder.to(device), y.to(device)\n\n        sequence = model.make_generation(X_encoder)\n\n        # print translation results\n        Generated_sentence = convert_to_sentence(sequence.cpu(), model.tgt_vocab)\n        Input_sentence = convert_to_sentence(X_encoder.squeeze(0).cpu(), model.src_vocab)\n        Label_sentence = convert_to_sentence(y.squeeze(0).cpu(), model.tgt_vocab)\n\n            \n    return Input_sentence, Label_sentence, Generated_sentence ","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:34.117052Z","iopub.execute_input":"2024-06-03T00:34:34.117386Z","iopub.status.idle":"2024-06-03T00:34:34.130614Z","shell.execute_reply.started":"2024-06-03T00:34:34.117357Z","shell.execute_reply":"2024-06-03T00:34:34.129652Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from typing import Dict, List, Tuple\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device = 'cpu') -> Dict[str, List]:\n    \n    # Create empty results dictionary\n    results = {\n        \"Training_Loss\": [],\n    }\n\n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n            Training_Loss = train_step(\n                data_loader=train_dataloader, \n                model=model, \n                loss_fn=loss_fn,\n                optimizer=optimizer,\n                epoch=epoch,\n                device=device\n            )\n            Translation_results = test_step(\n                data_loader=test_dataloader,\n                model=model,\n                device=device\n            )\n            # Print out what's happening\n            print(\n                f\"Epoch: {epoch} | Training_Loss: {Training_Loss:.4f} \\n\"\n                f\"Input_sentence: {Translation_results[0]}\\n\"\n                f\"Output_sentence: {Translation_results[1]}\\n\"\n                f\"Generated_sentence: {Translation_results[2]}\\n\"\n            )\n\n            # Update results dictionary\n            results[\"Training_Loss\"].append(Training_Loss.item())\n\n  # Return the filled results at the end of the epochs\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:34.132029Z","iopub.execute_input":"2024-06-03T00:34:34.132339Z","iopub.status.idle":"2024-06-03T00:34:34.145301Z","shell.execute_reply.started":"2024-06-03T00:34:34.132312Z","shell.execute_reply":"2024-06-03T00:34:34.144407Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def plot_results(Training_Loss):\n    plt.figure(figsize=(10,5))\n    \n    plt.plot(Training_Loss, color=\"blue\", label=\"Training Loss\")\n    plt.title(\"Training and Test Loss curves\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss value\")\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:34.146433Z","iopub.execute_input":"2024-06-03T00:34:34.146796Z","iopub.status.idle":"2024-06-03T00:34:34.159332Z","shell.execute_reply.started":"2024-06-03T00:34:34.146768Z","shell.execute_reply":"2024-06-03T00:34:34.158425Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Setup loss function and optimizer\nloss_fn = nn.CrossEntropyLoss(ignore_index=model_2.tgt_vocab['<pad>']) \noptimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.03)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:34.160513Z","iopub.execute_input":"2024-06-03T00:34:34.160834Z","iopub.status.idle":"2024-06-03T00:34:34.969228Z","shell.execute_reply.started":"2024-06-03T00:34:34.160805Z","shell.execute_reply":"2024-06-03T00:34:34.968226Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nset_seeds()\n\n# Measure time\nfrom timeit import default_timer as timer\ntrain_time_start = timer()\n\n# Setup the num_epochs hyperparameter\nNUM_EPOCHS = 700\n\nresults = train(model=model_2,\n                train_dataloader=train_dataloader,\n                test_dataloader=val_dataloader,\n                optimizer=optimizer,\n                loss_fn=loss_fn,\n                epochs=NUM_EPOCHS,\n                device=device)\n\ntrain_time_end = timer()\ntotal_train_time_model_2 = print_train_time(start=train_time_start,\n                                            end=train_time_end,\n                                            device=device)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T00:34:34.970418Z","iopub.execute_input":"2024-06-03T00:34:34.970927Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7a9bbaf11834f0f88b196a7090408a7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:380: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0 | Training_Loss: 7.6023 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: \n\nEpoch: 1 | Training_Loss: 6.3284 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> .\n\nEpoch: 2 | Training_Loss: 5.9648 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> .\n\nEpoch: 3 | Training_Loss: 5.7664 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> .\n\nEpoch: 4 | Training_Loss: 5.6297 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 5 | Training_Loss: 5.5230 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 6 | Training_Loss: 5.4339 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 7 | Training_Loss: 5.3610 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 8 | Training_Loss: 5.3019 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 9 | Training_Loss: 5.2481 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 10 | Training_Loss: 5.2029 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 11 | Training_Loss: 5.1594 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 12 | Training_Loss: 5.1235 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 13 | Training_Loss: 5.0895 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 14 | Training_Loss: 5.0577 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 15 | Training_Loss: 5.0280 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 16 | Training_Loss: 5.0010 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 17 | Training_Loss: 4.9732 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 18 | Training_Loss: 4.9507 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 19 | Training_Loss: 4.9260 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem <unk> und ein <unk> .\n\nEpoch: 20 | Training_Loss: 4.9071 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 21 | Training_Loss: 4.8854 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 22 | Training_Loss: 4.8682 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> und ein <unk> .\n\nEpoch: 23 | Training_Loss: 4.8489 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> auf einem <unk> .\n\nEpoch: 24 | Training_Loss: 4.8295 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem <unk> und ein <unk> .\n\nEpoch: 25 | Training_Loss: 4.8149 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> und ein <unk> .\n\nEpoch: 26 | Training_Loss: 4.7999 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem <unk> und ein <unk> .\n\nEpoch: 27 | Training_Loss: 4.7828 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann in einem <unk> und ein <unk> .\n\nEpoch: 28 | Training_Loss: 4.7694 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem <unk> und ein <unk> .\n\nEpoch: 29 | Training_Loss: 4.7549 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem <unk> und ein <unk> .\n\nEpoch: 30 | Training_Loss: 4.7433 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 31 | Training_Loss: 4.7291 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 32 | Training_Loss: 4.7156 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 33 | Training_Loss: 4.7033 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 34 | Training_Loss: 4.6955 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 35 | Training_Loss: 4.6812 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 36 | Training_Loss: 4.6697 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 37 | Training_Loss: 4.6584 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 38 | Training_Loss: 4.6501 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 39 | Training_Loss: 4.6392 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 40 | Training_Loss: 4.6286 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 41 | Training_Loss: 4.6199 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 42 | Training_Loss: 4.6086 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 43 | Training_Loss: 4.6012 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 44 | Training_Loss: 4.5919 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 45 | Training_Loss: 4.5843 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 46 | Training_Loss: 4.5767 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein <unk> .\n\nEpoch: 47 | Training_Loss: 4.5664 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 48 | Training_Loss: 4.5593 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 49 | Training_Loss: 4.5516 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 50 | Training_Loss: 4.5419 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 51 | Training_Loss: 4.5348 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 52 | Training_Loss: 4.5281 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 53 | Training_Loss: 4.5215 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 54 | Training_Loss: 4.5140 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 55 | Training_Loss: 4.5046 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann mit einem <unk> .\n\nEpoch: 56 | Training_Loss: 4.5003 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten und ein Mann in einem <unk> .\n\nEpoch: 57 | Training_Loss: 4.4923 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 58 | Training_Loss: 4.4859 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 59 | Training_Loss: 4.4798 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 60 | Training_Loss: 4.4732 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 61 | Training_Loss: 4.4652 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 62 | Training_Loss: 4.4574 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 63 | Training_Loss: 4.4531 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 64 | Training_Loss: 4.4465 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 65 | Training_Loss: 4.4389 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 66 | Training_Loss: 4.4334 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 67 | Training_Loss: 4.4259 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 68 | Training_Loss: 4.4192 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 69 | Training_Loss: 4.4123 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 70 | Training_Loss: 4.4054 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 71 | Training_Loss: 4.3976 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 72 | Training_Loss: 4.3918 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 73 | Training_Loss: 4.3846 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 74 | Training_Loss: 4.3780 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 75 | Training_Loss: 4.3721 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 76 | Training_Loss: 4.3673 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 77 | Training_Loss: 4.3588 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 78 | Training_Loss: 4.3551 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 79 | Training_Loss: 4.3497 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 80 | Training_Loss: 4.3444 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 81 | Training_Loss: 4.3395 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 82 | Training_Loss: 4.3343 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und ein Mann in einem <unk> .\n\nEpoch: 83 | Training_Loss: 4.3274 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 84 | Training_Loss: 4.3249 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 85 | Training_Loss: 4.3180 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 86 | Training_Loss: 4.3160 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 87 | Training_Loss: 4.3107 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 88 | Training_Loss: 4.3061 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 89 | Training_Loss: 4.3004 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 90 | Training_Loss: 4.2947 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 91 | Training_Loss: 4.2908 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 92 | Training_Loss: 4.2893 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 93 | Training_Loss: 4.2828 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 94 | Training_Loss: 4.2782 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 95 | Training_Loss: 4.2752 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 96 | Training_Loss: 4.2705 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> .\n\nEpoch: 97 | Training_Loss: 4.2655 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 98 | Training_Loss: 4.2638 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 99 | Training_Loss: 4.2569 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 100 | Training_Loss: 4.2553 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 101 | Training_Loss: 4.2506 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 102 | Training_Loss: 4.2479 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 103 | Training_Loss: 4.2432 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 104 | Training_Loss: 4.2380 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 105 | Training_Loss: 4.2336 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 106 | Training_Loss: 4.2280 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 107 | Training_Loss: 4.2233 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 108 | Training_Loss: 4.2163 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 109 | Training_Loss: 4.2150 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 110 | Training_Loss: 4.2085 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 111 | Training_Loss: 4.2048 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 112 | Training_Loss: 4.2022 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 113 | Training_Loss: 4.1963 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 114 | Training_Loss: 4.1946 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 115 | Training_Loss: 4.1918 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 116 | Training_Loss: 4.1844 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 117 | Training_Loss: 4.1823 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 118 | Training_Loss: 4.1793 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 119 | Training_Loss: 4.1762 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 120 | Training_Loss: 4.1720 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 121 | Training_Loss: 4.1693 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 123 | Training_Loss: 4.1590 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 124 | Training_Loss: 4.1574 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> und ein Mann in der Hand .\n\nEpoch: 125 | Training_Loss: 4.1529 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 126 | Training_Loss: 4.1519 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 127 | Training_Loss: 4.1474 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 128 | Training_Loss: 4.1426 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 129 | Training_Loss: 4.1402 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 130 | Training_Loss: 4.1360 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 131 | Training_Loss: 4.1324 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 132 | Training_Loss: 4.1307 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> und ein Mann in der Hand .\n\nEpoch: 133 | Training_Loss: 4.1264 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 134 | Training_Loss: 4.1244 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 135 | Training_Loss: 4.1209 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und eine Frau in einem <unk> , während ein Mann in der Hand .\n\nEpoch: 136 | Training_Loss: 4.1188 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 137 | Training_Loss: 4.1127 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 138 | Training_Loss: 4.1102 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 139 | Training_Loss: 4.1079 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine Frau in der Hand .\n\nEpoch: 140 | Training_Loss: 4.1036 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 141 | Training_Loss: 4.1000 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 142 | Training_Loss: 4.0950 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem weißen Hemd und eine Frau in einem <unk> und ein Mann in der Hand .\n\nEpoch: 143 | Training_Loss: 4.0918 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 144 | Training_Loss: 4.0878 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> und ein Mann in einem <unk> .\n\nEpoch: 145 | Training_Loss: 4.0834 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine Frau in der Hand .\n\nEpoch: 146 | Training_Loss: 4.0800 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 147 | Training_Loss: 4.0754 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 148 | Training_Loss: 4.0724 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine Frau in der Hand .\n\nEpoch: 149 | Training_Loss: 4.0698 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 150 | Training_Loss: 4.0655 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine Frau in der Hand .\n\nEpoch: 151 | Training_Loss: 4.0598 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine Frau in der Hand .\n\nEpoch: 152 | Training_Loss: 4.0571 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand .\n\nEpoch: 153 | Training_Loss: 4.0532 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine Frau in der Hand .\n\nEpoch: 154 | Training_Loss: 4.0497 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> und ein Mann in einem <unk> .\n\nEpoch: 155 | Training_Loss: 4.0441 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine Frau in der Hand .\n\nEpoch: 156 | Training_Loss: 4.0423 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine <unk> .\n\nEpoch: 157 | Training_Loss: 4.0389 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine <unk> .\n\nEpoch: 158 | Training_Loss: 4.0341 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine <unk> .\n\nEpoch: 159 | Training_Loss: 4.0327 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine <unk> .\n\nEpoch: 160 | Training_Loss: 4.0282 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine <unk> .\n\nEpoch: 161 | Training_Loss: 4.0250 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> und ein Mann in einem <unk> .\n\nEpoch: 162 | Training_Loss: 4.0201 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> und ein Mann in einem <unk> .\n\nEpoch: 163 | Training_Loss: 4.0199 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> und ein Mann in einem <unk> .\n\nEpoch: 164 | Training_Loss: 4.0162 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> , während ein Mann in der Hand und eine <unk> .\n\nEpoch: 165 | Training_Loss: 4.0137 \nInput_sentence: A man is performing a <unk> <unk> as people walk by and watch his performance .\nOutput_sentence: Ein Mann <unk> ein <unk> Kunststück , während Menschen vorbeilaufen und seiner Darbietung zuschauen .\nGenerated_sentence: Ein Mann mit einem roten Hemd und einem <unk> und ein Mann in einem <unk> .\n\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_results(results[\"Training_Loss\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\ntarget_dir_path = Path(\"/kaggle/working/experiment\")\ntarget_dir_path.mkdir(parents=True,exist_ok=True)\nmodel_name = 'simple_seq2seq.pt'\nmodel_save_path = target_dir_path / model_name\ntorch.save(obj=model_2.state_dict(), f=model_save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Prediction","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntest_df = pd.read_csv(\"/kaggle/input/machine-translation-dataset-de-en/translation_test.csv\")\ntest_df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\n\nen_tokenizer = get_tokenizer(tokenizer = 'spacy', language = \"en_core_web_sm\")\n\n# apply tokenizer to our dataset\ntokenized_en_test_df = test_df['english'].map(en_tokenizer)\ntokenized_en_test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchtext import transforms\n\ntest_transform = transforms.Sequential(\n    ## converts the sentences to indices based on given vocabulary\n    transforms.VocabTransform(vocab=en_vocab),\n\n    ## Add <sos> at beginning of each sentence. 1 because the index for <sos> in vocabulary is 1 as seen in previous section\n    transforms.AddToken(en_vocab['<sos>'], begin=True),\n\n    ## Add <eos> at end of each sentence. 2 because the index for <eos> in vocabulary is 2 as seen in previous section\n    transforms.AddToken(en_vocab['<sos>'], begin=False),\n    \n    ## converts data into tensor\n    transforms.ToTensor()\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_Dataset = En_De_DatasetCustom(\n    df = test_df,\n    transform = {'en': en_transform},\n    is_test = True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport os\n\n# Setup the batch size hyperparameter\nBATCH_SIZE = 1\nNUM_CORES = os.cpu_count()\n\n# Turn datasets into iterables (batches)\ntest_dataloader = DataLoader(\n    Test_Dataset, # dataset to turn into iterable\n    batch_size=BATCH_SIZE, # how many samples per batch? \n    shuffle = False,\n    num_workers = NUM_CORES,\n    pin_memory = True\n    \n)\n# Let's check out what we've created\nprint(f\"Dataloaders: {test_dataloader}\") \nprint(f\"Length of training dataset: {len(test_dataloader.dataset)}\")\nprint(f\"Length of train dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_predictions(model: torch.nn.Module, \n                     data_loader: torch.utils.data.DataLoader, \n                     device: torch.device = 'cpu'):\n    \n    if device != 'cpu':\n        model.to(device)\n   \n    model.eval()\n    with torch.inference_mode():\n        y = []\n        pbar = tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Predicting\")\n        for batch, X_encoder in pbar:\n            # Send data to GPU\n            if device != 'cpu':\n                X_encoder= X_encoder.to(device)\n            \n            sequence = model.make_generation(X_encoder)\n            Generated_sentence = convert_to_sentence(sequence.cpu(), model.tgt_vocab)\n            y.append(Generated_sentence)\n        \n    return y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = make_predictions(\n    model = model_2, \n    data_loader = test_dataloader, \n    device = device)\n    \ntest_df['generated'] = predictions\n\nprint(test_df['english'][7], test_df['german'][7], test_df['generated'][7], sep = '\\n')\nprint()\nprint(test_df['english'][9], test_df['german'][9], test_df['generated'][9], sep = '\\n')\nprint()\nprint(test_df['english'][12], test_df['german'][12], test_df['generated'][12], sep = '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}